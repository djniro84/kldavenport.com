<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning on Kevin Davenport Engineering &amp; ML blog</title>
    <link>https://kldavenport.netlify.com/tags/reinforcement-learning/</link>
    <description>Recent content in Reinforcement Learning on Kevin Davenport Engineering &amp; ML blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 Jan 2018 11:54:26 -0800</lastBuildDate>
    
	<atom:link href="https://kldavenport.netlify.com/tags/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sutton&#39;s Temporal Difference Learning</title>
      <link>https://kldavenport.netlify.com/suttons-temporal-difference-learning/</link>
      <pubDate>Sun, 21 Jan 2018 11:54:26 -0800</pubDate>
      
      <guid>https://kldavenport.netlify.com/suttons-temporal-difference-learning/</guid>
      <description>A critical aspect of research is the reproduction of previously published results. Yet most will find reproduction of research challenging since important parameters needed to reproduce results are often not stated in the papers. I’ve noticed nn the past 5 years there has been a sort of catharsis regarding the lack of reproducibility [1][2][3]. This isn’t an issue for wetlab science alone [4]. The obvious benefit of reproduction is to aid in your own understanding of the results.</description>
    </item>
    
  </channel>
</rss>